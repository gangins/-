{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled6.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyN8nsrXj6ipChXrq777POak",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/gangins/-/blob/main/Untitled6.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RTGZPYxgMOS_",
        "outputId": "44e2d4e1-62eb-450e-ad9c-afa94a6728c3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1.12.1+cu113\n"
          ]
        }
      ],
      "source": [
        "import torch\n",
        "\n",
        "print(torch.__version__)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#x의 연산과적을 추적하기 위해 requires_grad=True로 설정\n",
        "x = torch.ones(2, 2, requires_grad=True)\n",
        "print(x)\n",
        "\n",
        "#직접 생성한 tensor이기 때문에 grad_fn이 none 인것을 확인 할 수 있음"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c3mVUI7MRDOg",
        "outputId": "c5e84862-239d-4cfb-c643-1ff63718f20d"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[1., 1.],\n",
            "        [1., 1.]], requires_grad=True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#y는 연산의 결과로 생성된 것이기 때문에 grad_fn을 갖고 있는 것을 확인 가능\n",
        "\n",
        "y = x+2\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QpChEvzfSQn3",
        "outputId": "1c19641f-eb07-4984-aae9-2febcf31dbea"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[3., 3.],\n",
            "        [3., 3.]], grad_fn=<AddBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 연산의 결과로 생성된 것이기 때문에  grad_fn을 갖고 있는 것을 확인 가능"
      ],
      "metadata": {
        "id": "YfcJS7QBSgH1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(y.grad_fn)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "k6A90XfsSgKe",
        "outputId": "b4e3296c-8f00-4c9e-d2c5-1c58399230a7"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<AddBackward0 object at 0x7ffac865f810>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "z = y*y*3\n",
        "out = z.mean()\n",
        "\n",
        "#각각 사용한 func에 맞게 grad_fn이 생성된 것을 확인할 수 있음\n",
        "print(z)\n",
        "print(out)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gEmn6fo_SgNI",
        "outputId": "c790a81e-c91b-4346-ed1b-f7dd24fb81a3"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[27., 27.],\n",
            "        [27., 27.]], grad_fn=<MulBackward0>)\n",
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "requires_grad_()를 사용하면 기존 Tensor의 requires_grad 값을 바꿀수 있음\n",
        "입력값이 지정되지 않으면 기본값은 FAlse\n"
      ],
      "metadata": {
        "id": "kpoUeu2uSgP1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        ""
      ],
      "metadata": {
        "id": "JiBZmocZTvut"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "a = torch.randn(2,2)\n",
        "print(a)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PVFGbXbhSgSs",
        "outputId": "bf0d1359-f30f-49bc-b86a-99c7974440fb"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[ 0.8092,  0.4518],\n",
            "        [-0.7354, -0.9325]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a = ((a*3)/ (a-1))\n",
        "print(a)\n",
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "nCRWqMGsT9Bs",
        "outputId": "1a88f51a-3bc8-4c4c-9821-1da0e43e2b96"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[-12.7212,  -2.4725],\n",
            "        [  1.2713,   1.4476]])\n",
            "False\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "a.requires_grad_(True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sdtp84UqT9Ee",
        "outputId": "90c8d9c4-3e30-4040-97e7-c2df7dbe9274"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[-12.7212,  -2.4725],\n",
              "        [  1.2713,   1.4476]], requires_grad=True)"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(a.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lnW_0JQcUMLJ",
        "outputId": "57fd5dd5-8186-41ce-8915-36873e977500"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "b = (a*a).sum()\n",
        "print(b)\n",
        "print(b.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hyThnXTDUODy",
        "outputId": "46fae6c8-0f10-4e0f-a232-e1ed368995e6"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(171.6529, grad_fn=<SumBackward0>)\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "변화도(Gradient)"
      ],
      "metadata": {
        "id": "Nv9xu87oUa54"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        " print(out)\n",
        "\n",
        " # 이전에 만든 out을 사용해서 역전파 진행\n",
        "\n",
        "\n",
        "y.retain_grad()   # 중간 값에 대한 미분 값을 보고싶다면 해당 갑셍 대한 retain_grad()을 호출해야함\n",
        "z.retain_grad()\n",
        "out.backward() # 여러번 미분을 진행하기 위해서는 retain_graph=True로 설정해 줘야함 (그렇지 않으면 아래처럼 에러 발생)\n",
        "\n",
        "#out.backward(torch.tensor(1.))을 진행하는 것과 동일\n",
        "\n",
        "print(x.grad)\n",
        "\n",
        "print(y.grad)\n",
        "\n",
        "print(z.grad)\n",
        "\n",
        "print(z.is_leaf)\n",
        "\n",
        "out.backward()\n",
        "print(x.grad)\n",
        "\n",
        "print(y.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 474
        },
        "id": "uEEGH1fdUfQI",
        "outputId": "3c119363-73e3-44fd-a183-21fc7d0d0e37"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor(27., grad_fn=<MeanBackward0>)\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-18-2b37d0c7b19f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m   \u001b[0;31m# 중간 값에 대한 미분 값을 보고싶다면 해당 갑셍 대한 retain_grad()을 호출해야함\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0mz\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretain_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# 여러번 미분을 진행하기 위해서는 retain_graph=True로 설정해 줘야함 (그렇지 않으면 아래처럼 에러 발생)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;31m#out.backward(torch.tensor(1.))을 진행하는 것과 동일\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    394\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    395\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 396\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    397\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    398\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mRuntimeError\u001b[0m: Trying to backward through the graph a second time (or directly access saved tensors after they have already been freed). Saved intermediate values of the graph are freed when you call .backward() or autograd.grad(). Specify retain_graph=True if you need to backward through the graph a second time or if you need to access saved tensors after calling backward."
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(x.grad)\n",
        "print(y.grad)\n",
        "print(z.grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "h9RtUGseUfSq",
        "outputId": "d1347e0e-5845-4bfd-8389-bfaf6f70731f"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n",
            "tensor([[4.5000, 4.5000],\n",
            "        [4.5000, 4.5000]])\n",
            "tensor([[0.5000, 0.5000],\n",
            "        [0.5000, 0.5000]])\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x = torch.randn(3, requires_grad=True)\n",
        "print(x)\n",
        "y = x * 2\n",
        "print(y)\n",
        "\n",
        "#.data.norm() : L2 norm(Frobenius norm)\n",
        "#=sqrt(sum(y의 모든 요소^2))\n",
        "while y.data.norm() < 1000:\n",
        "  y = y * 2\n",
        "\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ChUTo6GMUfVJ",
        "outputId": "a12cfdbe-e95c-435c-b7f9-998558c67c6d"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "tensor([-0.7339, -0.5410,  1.7330], requires_grad=True)\n",
            "tensor([-1.4678, -1.0820,  3.4661], grad_fn=<MulBackward0>)\n",
            "tensor([-375.7690, -276.9923,  887.3200], grad_fn=<MulBackward0>)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#with torch.no_grad()로 코드를 감싸서 autograd가 .requires_grad=True인 Tensor의 연산 기록을 추적하는 걸 멈추게 할 수 있음\n",
        "print(x.requires_grad)\n",
        "with torch.no_grad():\n",
        "\tprint(x.requires_grad)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Osqr-0meUfYH",
        "outputId": "cfbe0b89-2670-4bf9-c16e-2f4acae4a11d"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "True\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#또는 .detach()를 호출하여 내용물은 같지만 requires_grad가 다른 새로운 Tensor를 생성할 수도 있음\n",
        "print(x.requires_grad)\n",
        "y=x.detach()\n",
        "print(y.requires_grad)\n",
        "print(x.eq(y).all())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gBOhlHG4Ufa-",
        "outputId": "c44f8630-1c01-403a-f973-dea6600dfefc"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "True\n",
            "False\n",
            "tensor(True)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#라이브러리 import\n",
        "import pandas as pd\n",
        "\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import DataLoader, TensorDataset"
      ],
      "metadata": {
        "id": "CNE3SilDUfdk"
      },
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class Net(nn.Module):\n",
        "\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "\n",
        "        self.layer0 = nn.Linear(4, 128)\n",
        "        self.layer1 = nn.Linear(128, 64)\n",
        "        self.layer2 = nn.Linear(64, 32)\n",
        "        self.layer3 = nn.Linear(32, 16)\n",
        "        self.layer4 = nn.Linear(16, 3)\n",
        "\n",
        "        self.bn0 = nn.BatchNorm1d(128)\n",
        "        self.bn1 = nn.BatchNorm1d(64)\n",
        "        self.bn2 = nn.BatchNorm1d(32)\n",
        "\n",
        "        self.act = nn.ReLU()\n",
        "\n",
        "    def forward(self, x):\n",
        "      x = self.act(self.bn0(self.layer0(x)))\n",
        "      x = self.act(self.bn1(self.layer1(x)))\n",
        "      x = self.act(self.bn2(self.layer2(x)))\n",
        "      x = self.act(self.layer3(x))\n",
        "      x = self.layer4(x)\n",
        "\n",
        "      return x"
      ],
      "metadata": {
        "id": "rcN4l2aIUfgs"
      },
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "손실함수(Loss function)\n",
        "(output, target)을 한 쌍으로 입력받아 출력이 정답으로부터 얼마나 떨어져있는지 계산\n",
        "forward()만 정의하면 backward()는 autograd에 의해 자동 정의\n",
        "모델의 학습 가능한 매개변수는 net.parameters()에 의해 변환"
      ],
      "metadata": {
        "id": "ju931srTUfjj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "ex_X, ex_y = torch.randn([4, 4]), torch.tensor([1, 0, 2, 0])\n",
        "print('ex_X : ', ex_X)\n",
        "print('ex_y : ', ex_y)\n",
        "\n",
        "#모델 정의\n",
        "net = Net()\n",
        "#입력값을 모델로 훈련시킨 후 나온 출력값\n",
        "output = net(ex_X)\n",
        "print(output)\n",
        "#손실계산\n",
        "loss = criterion(output, ex_y)\n",
        "#계산한 손실 출력\n",
        "print('loss: ', loss.item())\n",
        "  \n",
        "net.zero_grad()\n",
        "\n",
        "print('layer0.bias.grad before backward')\n",
        "print(net.layer4.bias.grad)\n",
        "print(net.layer4.bias.is_leaf)\n",
        "\n",
        "loss.backward()\n",
        "\n",
        "print('layer0.bias.grad after backward')\n",
        "print(net.layer4.bias.grad)\n",
        "\n",
        "'''\n",
        "ex_X :  tensor([[-0.3045,  1.5439,  0.6195, -0.4642],\n",
        "        [ 2.3502,  0.7011,  0.1095,  1.6037],\n",
        "        [ 0.8238,  0.8151, -0.0307,  0.5803],\n",
        "        [-0.6257,  0.8074, -0.0829,  0.3538]])\n",
        "ex_y :  tensor([1, 0, 2, 0])\n",
        "tensor([[ 0.4725, -0.5172,  0.0757],\n",
        "        [ 0.2162, -0.0060,  0.1769],\n",
        "        [ 0.1057, -0.1521,  0.0456],\n",
        "        [ 0.2338, -0.3210,  0.1688]], grad_fn=<AddmmBackward>)\n",
        "loss:  1.1750612258911133\n",
        "layer0.bias.grad before backward\n",
        "None\n",
        "True\n",
        "layer0.bias.grad after backward\n",
        "tensor([-0.0955, -0.0037,  0.0993])\n",
        "'''"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 366
        },
        "id": "c4KDwiBTY80O",
        "outputId": "31a0f500-21ea-4c01-f616-a47eac77796e"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "ex_X :  tensor([[-0.5512,  0.1042,  1.1292, -0.8212],\n",
            "        [-0.6133, -2.0559,  0.2395, -1.5817],\n",
            "        [ 1.7028,  0.5092, -1.3381, -0.8511],\n",
            "        [ 1.2615, -0.3084,  0.4157,  1.5285]])\n",
            "ex_y :  tensor([1, 0, 2, 0])\n",
            "tensor([[ 0.0085,  0.1776,  0.1056],\n",
            "        [-0.0624,  0.0907,  0.1551],\n",
            "        [ 0.0111,  0.1013,  0.3250],\n",
            "        [ 0.0754,  0.1743,  0.2315]], grad_fn=<AddmmBackward0>)\n",
            "loss:  1.0902047157287598\n",
            "layer0.bias.grad before backward\n",
            "None\n",
            "True\n",
            "layer0.bias.grad after backward\n",
            "tensor([-0.2020,  0.0889,  0.1131])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'\\nex_X :  tensor([[-0.3045,  1.5439,  0.6195, -0.4642],\\n        [ 2.3502,  0.7011,  0.1095,  1.6037],\\n        [ 0.8238,  0.8151, -0.0307,  0.5803],\\n        [-0.6257,  0.8074, -0.0829,  0.3538]])\\nex_y :  tensor([1, 0, 2, 0])\\ntensor([[ 0.4725, -0.5172,  0.0757],\\n        [ 0.2162, -0.0060,  0.1769],\\n        [ 0.1057, -0.1521,  0.0456],\\n        [ 0.2338, -0.3210,  0.1688]], grad_fn=<AddmmBackward>)\\nloss:  1.1750612258911133\\nlayer0.bias.grad before backward\\nNone\\nTrue\\nlayer0.bias.grad after backward\\ntensor([-0.0955, -0.0037,  0.0993])\\n'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 25
        }
      ]
    }
  ]
}